# Контрольные вопросы к Assignment 2
## OpenMP, CUDA и гетерогенные вычисления

---

### 1. Что понимается под гетерогенной параллелизацией?

Гетерогенная параллелизация - это подход к вычислениям, когда используются разные типы вычислительных устройств одновременно. Обычно это комбинация CPU и GPU.

**Простыми словами:** мы используем разные процессоры для разных задач. CPU хорошо справляется со сложной логикой, а GPU - с простыми операциями над большим количеством данных.

**Пример:** В программе машинного обучения:
- CPU загружает и подготавливает данные
- GPU обучает нейронную сеть (делает миллионы умножений матриц)
- CPU сохраняет результаты

---

### 2. В чём принципиальные различия архитектур CPU и GPU?

| Характеристика | CPU | GPU |
|----------------|-----|-----|
| Количество ядер | Мало (4-32) | Много (сотни, тысячи) |
| Мощность ядра | Высокая | Низкая |
| Частота | Высокая (3-5 ГГц) | Низкая (1-2 ГГц) |
| Кэш | Большой | Маленький |
| Управление потоками | Сложное | Простое (SIMD) |
| Ветвления (if-else) | Быстрые | Медленные |
| Задержка операций | Низкая | Высокая |
| Пропускная способность | Средняя | Очень высокая |

**CPU** - как несколько очень умных работников, которые могут делать сложные задачи.

**GPU** - как тысячи простых работников, которые делают одинаковые операции.

---

### 3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?

**Задачи для GPU:**
- Обработка изображений и видео (фильтры применяются к каждому пикселю)
- Матричные операции (умножение матриц в нейронных сетях)
- Физические симуляции (расчет движения частиц)
- Криптография (подбор хешей)
- Рендеринг 3D графики

**Характеристики задач для GPU:**
- Много данных
- Одинаковые операции над разными данными
- Мало зависимостей между операциями
- Мало ветвлений

**Задачи для CPU:**
- Операционная система
- Работа с файлами и сетью
- Сложная логика с ветвлениями
- Обработка пользовательского ввода
- Компиляция программ
- Базы данных

**Характеристики задач для CPU:**
- Сложные алгоритмы
- Много условий и ветвлений
- Последовательные зависимости
- Работа с разнородными данными

---

### 4. Почему не все алгоритмы эффективно распараллеливаются с использованием OpenMP?

**Причины:**

1. **Зависимости по данным**
   Если каждый шаг зависит от предыдущего, параллелизм невозможен.
   ```cpp
   // Нельзя распараллелить - каждый элемент зависит от предыдущего
   for (int i = 1; i < n; i++) {
       arr[i] = arr[i-1] * 2;
   }
   ```

2. **Накладные расходы**
   Создание потоков и синхронизация занимают время. Для маленьких задач это может быть дольше чем сами вычисления.

3. **Критические секции**
   Если потоки часто обращаются к общим данным, они блокируют друг друга.

4. **Несбалансированная нагрузка**
   Если один поток делает больше работы, остальные простаивают.

5. **Алгоритмическая сложность**
   Некоторые алгоритмы по своей природе последовательны (например, поиск в глубину в графе).

**Закон Амдала:** Ускорение ограничено долей последовательного кода. Если 20% кода нельзя распараллелить, максимальное ускорение = 5x, независимо от числа процессоров.

---

### 5. В чём заключается основная идея алгоритма сортировки слиянием?

**Идея:** "Разделяй и властвуй"

**Шаги:**
1. **Разделить** массив на две половины
2. **Рекурсивно** отсортировать каждую половину
3. **Слить** две отсортированные половины в один отсортированный массив

**Пример:**
```
[8, 4, 3, 7, 6, 5, 2, 1]  - исходный массив
        ↓
[8, 4, 3, 7] | [6, 5, 2, 1]  - делим пополам
    ↓              ↓
[8,4]|[3,7]    [6,5]|[2,1]   - делим еще
  ↓     ↓        ↓     ↓
[4,8] [3,7]    [5,6] [1,2]   - сортируем пары
    ↓              ↓
[3, 4, 7, 8] | [1, 2, 5, 6]  - сливаем
        ↓
[1, 2, 3, 4, 5, 6, 7, 8]     - финальное слияние
```

**Сложность:** O(n log n) - эффективно для больших массивов.

**Преимущество для параллелизма:** На каждом уровне слияния операции независимы.

---

### 6. Какие сложности возникают при реализации сортировки слиянием на GPU?

**Основные сложности:**

1. **Копирование данных**
   Данные нужно скопировать с CPU на GPU и обратно. Это занимает время и может свести на нет выигрыш от параллелизма.

2. **Рекурсия**
   GPU плохо работает с рекурсией. Нужно переписать алгоритм итеративно (снизу вверх).

3. **Неравномерная загрузка**
   На первых этапах много маленьких массивов для слияния. На последних - мало больших. Загрузка GPU неравномерна.

4. **Синхронизация**
   После каждого уровня слияния нужна синхронизация всех потоков. Это снижает производительность.

5. **Память**
   Слияние требует дополнительную память O(n). На GPU память ограничена.

6. **Ветвления при слиянии**
   Операция слияния содержит условия (if-else), что неэффективно на GPU.

7. **Выбор размера блоков**
   Нужно подобрать оптимальный размер блоков под конкретный GPU.

---

### 7. Как выбор размера блока и сетки влияет на производительность вычислений на GPU?

**Термины:**
- **Блок** - группа потоков, которые выполняются вместе
- **Сетка** - набор всех блоков
- **Warp** - группа из 32 потоков, выполняемых одновременно (на NVIDIA)

**Влияние размера блока:**

1. **Слишком маленький блок (< 32 потоков)**
   - Неполный warp = потраченные ресурсы
   - Плохая утилизация GPU

2. **Слишком большой блок**
   - Может не хватить регистров и shared memory
   - Меньше блоков выполняется одновременно

3. **Оптимальный размер**
   - Обычно 128, 256, или 512 потоков
   - Кратен размеру warp (32)
   - Зависит от конкретного алгоритма и GPU

**Влияние размера сетки:**

1. **Мало блоков**
   - GPU недозагружен
   - Не все мультипроцессоры работают

2. **Много блоков**
   - Хорошая загрузка GPU
   - Возможность скрыть латентность памяти

**Рекомендации:**
- Размер блока кратен 32 (размер warp)
- Число блоков >= число мультипроцессоров * 2
- Экспериментировать для конкретной задачи

---

### 8. Почему гетерогенный подход может быть эффективнее использования только CPU или только GPU?

**Причины:**

1. **Использование сильных сторон каждого устройства**
   - CPU эффективен для последовательной логики
   - GPU эффективен для параллельных вычислений
   - Гетерогенный подход использует оба преимущества

2. **Параллельная работа CPU и GPU**
   Пока GPU считает, CPU может готовить следующую порцию данных.
   ```
   CPU: [подготовка данных 1][подготовка данных 2][подготовка данных 3]
   GPU:                     [обработка 1]        [обработка 2]
   ```

3. **Оптимальное распределение задач**
   Каждая часть программы выполняется там, где быстрее.

4. **Масштабируемость**
   Можно использовать несколько GPU + CPU одновременно.

5. **Сокрытие задержек**
   Пока данные копируются на GPU, CPU выполняет другую работу.

**Пример (обработка видео):**
- CPU: читает файл, декодирует кадры
- GPU: применяет фильтры к кадрам
- CPU: кодирует и сохраняет результат

Если бы всё делал только CPU или только GPU - было бы медленнее, потому что:
- CPU медленно применяет фильтры к миллионам пикселей
- GPU неэффективен для работы с файлами и декодирования

**Вывод:** Гетерогенный подход позволяет получить максимальную производительность, выбирая оптимальное устройство для каждой части задачи.
